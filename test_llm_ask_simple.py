#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆLLM askæ–¹æ³•æµ‹è¯•ç¨‹åº
"""

import asyncio
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.llm import LLM
from app.schema import Message


async def test_simple_ask():
    """ç®€å•çš„askæ–¹æ³•æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•LLM askæ–¹æ³•...")

    try:
        # åˆ›å»ºLLMå®ä¾‹
        llm = LLM()
        print(f"âœ… LLMåˆå§‹åŒ–æˆåŠŸ")
        print(f"   æ¨¡å‹: {llm.model}")
        print(f"   APIç±»å‹: {llm.api_type}")
        print(f"   æœ€å¤§tokenæ•°: {llm.max_tokens}")

        # æµ‹è¯•åŸºæœ¬å¯¹è¯
        print("\nğŸ“ æµ‹è¯•åŸºæœ¬å¯¹è¯...")
        messages = [Message.user_message("ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")]

        response = await llm.ask(messages, stream=False)
        print(f"âœ… æ”¶åˆ°å“åº”: {response}")

        # æµ‹è¯•å¸¦ç³»ç»Ÿæ¶ˆæ¯çš„å¯¹è¯
        print("\nğŸ”§ æµ‹è¯•å¸¦ç³»ç»Ÿæ¶ˆæ¯çš„å¯¹è¯...")
        system_msgs = [Message.system_message("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¼–ç¨‹åŠ©æ‰‹ã€‚")]
        messages = [Message.user_message("ä»€ä¹ˆæ˜¯Pythonè£…é¥°å™¨ï¼Ÿ")]

        response = await llm.ask(messages, system_msgs=system_msgs, stream=False)
        print(f"âœ… æ”¶åˆ°å“åº”: {response}")

        # æµ‹è¯•æµå¼å“åº”
        print("\nğŸŒŠ æµ‹è¯•æµå¼å“åº”...")
        messages = [Message.user_message("è¯·å†™ä¸€ä¸ªç®€å•çš„Pythonå‡½æ•°ã€‚")]

        response = await llm.ask(messages, stream=True)
        print(f"âœ… æµå¼å“åº”å®Œæˆ: {response}")

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    success = await test_simple_ask()
    return 0 if success else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)


