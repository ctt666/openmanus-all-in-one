#!/usr/bin/env python3
"""
è°ƒè¯• ask æ–¹æ³• 400 é”™è¯¯çš„è„šæœ¬
"""

import asyncio
import json

from app.llm import LLM
from app.schema import Message, Role


async def debug_ask_400():
    """è°ƒè¯•askæ–¹æ³•400é”™è¯¯"""
    print("ğŸ§ª å¼€å§‹è°ƒè¯• ask æ–¹æ³• 400 é”™è¯¯...")

    # åˆ›å»ºLLMå®ä¾‹
    llm = LLM()

    # æ¨¡æ‹Ÿæ¶ˆæ¯ - ä½¿ç”¨ä¸é”™è¯¯æ—¥å¿—ä¸­ç›¸åŒçš„å†…å®¹
    messages = [Message.user_message("å¸®æˆ‘åˆ¶å®šä¸€ä»½å‘¨æœ«è®¡åˆ’ï¼Œä¸æ¸…æ¥šçš„é—®æˆ‘")]

    print("ğŸ“ æ¶ˆæ¯å†…å®¹:")
    for msg in messages:
        print(f"  - {msg.to_dict()}")

    try:
        print("\nğŸš€ è°ƒç”¨ ask æ–¹æ³•...")
        response = await llm.ask(messages=messages, stream=False)
        print(f"âœ… æˆåŠŸè·å¾—å“åº”: {response}")

    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {type(e).__name__}: {e}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯éªŒè¯é”™è¯¯
        if hasattr(e, "__cause__") and e.__cause__:
            print(f"   åŸå› : {type(e.__cause__).__name__}: {e.__cause__}")

        # æ£€æŸ¥æ¶ˆæ¯æ ¼å¼
        print("\nğŸ” æ£€æŸ¥æ¶ˆæ¯æ ¼å¼...")
        try:
            formatted_messages = llm.format_messages(messages, supports_images=False)
            print("âœ… æ¶ˆæ¯æ ¼å¼éªŒè¯é€šè¿‡")
            for msg in formatted_messages:
                print(f"  - {json.dumps(msg, indent=2, ensure_ascii=False)}")
        except Exception as format_error:
            print(f"âŒ æ¶ˆæ¯æ ¼å¼éªŒè¯å¤±è´¥: {format_error}")

        # æ£€æŸ¥Tokené™åˆ¶
        print("\nğŸ” æ£€æŸ¥Tokené™åˆ¶...")
        try:
            input_tokens = llm.count_message_tokens(messages)
            print(f"è¾“å…¥Tokenæ•°é‡: {input_tokens}")
            if llm.check_token_limit(input_tokens):
                print("âœ… Tokenæ•°é‡åœ¨é™åˆ¶èŒƒå›´å†…")
            else:
                print("âŒ Tokenæ•°é‡è¶…å‡ºé™åˆ¶")
                error_message = llm.get_limit_error_message(input_tokens)
                print(f"é”™è¯¯ä¿¡æ¯: {error_message}")
        except Exception as token_error:
            print(f"âŒ Tokenæ£€æŸ¥å¤±è´¥: {token_error}")


def test_message_validation():
    """æµ‹è¯•æ¶ˆæ¯éªŒè¯"""
    print("\nğŸ§ª æµ‹è¯•æ¶ˆæ¯éªŒè¯...")

    # æµ‹è¯•ä¸åŒç±»å‹çš„æ¶ˆæ¯
    test_cases = [
        ("ç”¨æˆ·æ¶ˆæ¯", Message.user_message("æµ‹è¯•å†…å®¹")),
        ("ç³»ç»Ÿæ¶ˆæ¯", Message.system_message("ç³»ç»Ÿæç¤º")),
        ("åŠ©æ‰‹æ¶ˆæ¯", Message.assistant_message("åŠ©æ‰‹å›å¤")),
    ]

    for name, msg in test_cases:
        try:
            msg_dict = msg.to_dict()
            print(f"âœ… {name}: {msg_dict}")

            # æ£€æŸ¥è§’è‰²æ˜¯å¦æœ‰æ•ˆ
            if msg_dict["role"] in ["system", "user", "assistant", "tool"]:
                print(f"  âœ… è§’è‰² '{msg_dict['role']}' æœ‰æ•ˆ")
            else:
                print(f"  âŒ è§’è‰² '{msg_dict['role']}' æ— æ•ˆ")

        except Exception as e:
            print(f"âŒ {name}: {e}")


def test_llm_config():
    """æµ‹è¯•LLMé…ç½®"""
    print("\nğŸ§ª æµ‹è¯•LLMé…ç½®...")

    try:
        llm = LLM()
        print(f"âœ… æ¨¡å‹: {llm.model}")
        print(f"âœ… æœ€å¤§Token: {llm.max_tokens}")
        print(f"âœ… æ¸©åº¦: {llm.temperature}")
        print(f"âœ… å®¢æˆ·ç«¯: {type(llm.client).__name__}")

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾åƒ
        from app.llm import MULTIMODAL_MODELS

        if llm.model in MULTIMODAL_MODELS:
            print(f"âœ… æ¨¡å‹æ”¯æŒå›¾åƒ")
        else:
            print(f"â„¹ï¸ æ¨¡å‹ä¸æ”¯æŒå›¾åƒ")

    except Exception as e:
        print(f"âŒ LLMé…ç½®æ£€æŸ¥å¤±è´¥: {e}")


async def test_simple_ask():
    """æµ‹è¯•ç®€å•çš„askè°ƒç”¨"""
    print("\nğŸ§ª æµ‹è¯•ç®€å•askè°ƒç”¨...")

    try:
        llm = LLM()

        # æœ€ç®€å•çš„æ¶ˆæ¯
        simple_messages = [{"role": "user", "content": "Hello"}]

        print("ğŸ“ ç®€å•æ¶ˆæ¯:")
        for msg in simple_messages:
            print(f"  - {msg}")

        response = await llm.ask(messages=simple_messages, stream=False)
        print(f"âœ… ç®€å•askè°ƒç”¨æˆåŠŸ: {response}")

    except Exception as e:
        print(f"âŒ ç®€å•askè°ƒç”¨å¤±è´¥: {e}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯APIé…ç½®é—®é¢˜
        if "authentication" in str(e).lower() or "api key" in str(e).lower():
            print("ğŸ”‘ å¯èƒ½æ˜¯APIå¯†é’¥é…ç½®é—®é¢˜")
        elif "rate limit" in str(e).lower():
            print("â±ï¸ å¯èƒ½æ˜¯é€Ÿç‡é™åˆ¶é—®é¢˜")
        elif "model" in str(e).lower():
            print("ğŸ¤– å¯èƒ½æ˜¯æ¨¡å‹é…ç½®é—®é¢˜")
        else:
            print("â“ æœªçŸ¥é”™è¯¯ç±»å‹")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Ask æ–¹æ³• 400 é”™è¯¯è°ƒè¯•å·¥å…·")
    print("=" * 50)

    # æµ‹è¯•LLMé…ç½®
    test_llm_config()

    # æµ‹è¯•æ¶ˆæ¯éªŒè¯
    test_message_validation()

    # æµ‹è¯•ç®€å•askè°ƒç”¨
    await test_simple_ask()

    # è°ƒè¯•åŸå§‹é—®é¢˜
    await debug_ask_400()

    print("\nğŸ‰ è°ƒè¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())
